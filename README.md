# Project 1 Generative Text

Yifan Hou, yihou@ucsd.edu


## Abstract

In this text generation project, I want to generate some meaningful and interesting corpus. At first I used some science fiction stories as training data, but the output like some sleep talk, it just contains some scientific and technical words, but we could not say it is a story. Due to the GPU is limited, it is hard to generate a whole story. So I change the training data, and choose short jokes as training data. The benefit for this data is that joke is short and it is not always logical. The joke generated by machine might give us some suprise. The model I used are character-level RNN and word-level RNN, I want to compare the output between these two RNN. 


## Model/Data

- training model is RNN model.
- training data 

## Code


Your code for generating your project:
- training_code.py or training_code.ipynb - your training code
- generative_code.py or generative_code.ipynb - your generation code

## Results

- Documentation of your generative text in an effective form. A file with your generated text (.pdf, .doc, .txt). 

## Technical Notes

Any implementation details or notes we need to repeat your work. 
- Does this code require other pip packages, software, etc?
- Does it run on some other (non-datahub) platform? (CoLab, etc.)

## Reference

References to any papers, techniques, repositories you used:
- Papers
  - [This is a paper](this_is_the_link.pdf)
- Repositories
- Blog posts
